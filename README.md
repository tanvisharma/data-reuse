# A Water-Flow Analogy for Teaching Data Reuse and  Memory Hierarchies

[![DOI](https://sandbox.zenodo.org/badge/1006065997.svg)](https://handle.stage.datacite.org/10.5072/zenodo.276218)

Deep Learning kernels, such as general matrix multiplications (GEMMs), exhibit high data‑reuse or operations per byte. However, internalizing the performance benefit of reuse, especially for undergraduates, can be difficult, as it depends on interactions between memory hierarchy and compute units. We introduce an intuitive water-flow analogy for a simple memory-compute model to clarify how bandwidth, on‑chip memory, and compute throughput interact to determine performance. In this analogy, DRAM is the tank; the memory controller is a tap with limited flow and latency; SRAM is the bucket; compute units are the dish‑washer. Using this analogy, we show how increasing data reuse rate‑matches compute throughput to memory bandwidth. Further, we provide worked examples to illustrate compute- and memory- bound scenarios in roofline performance model and latency-bound performance scenario, enabling students to predict performance benefit of reuse from first principles in one class. We also share ready‑to‑use slides for quick inclusion of the approach in undergraduate courses. By grounding architectural ideas in physical world scenario, our water‑flow analogy helps in longer retention of concepts related to data reuse and memory hierarchy.


Paper Link coming soon.
